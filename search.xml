<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>cross: rust 的跨平台编译利器</title>
    <url>/posts/3d1fe733/</url>
    <content><![CDATA[<h2 id="1-cross-介绍"><a href="#1-cross-介绍" class="headerlink" title="1. cross 介绍"></a>1. cross 介绍</h2><p>cross 是 <code>0</code> 配置的 Rust 跨平台编译工具，它有着使用简单、功能强大的特点，极大地方便了 rust 跨平台项目的构建、测试和发布。</p>
<h2 id="2-cargo-跨平台编译及问题"><a href="#2-cargo-跨平台编译及问题" class="headerlink" title="2. cargo 跨平台编译及问题"></a>2. cargo 跨平台编译及问题</h2><h3 id="2-1-cargo-跨平台编译"><a href="#2-1-cargo-跨平台编译" class="headerlink" title="2.1 cargo 跨平台编译"></a>2.1 cargo 跨平台编译</h3><p>cargo 本身支持跨平台编译，一般使用有如下命令：</p>
<ul>
<li><p>查看 target 列表<br><code>rustup target list</code></p>
</li>
<li><p>安装新的 target，以 <code>i686-unknown-linux-gnu</code> 为例<br><code>rustup target add i686-unknown-linux-gnu</code></p>
</li>
<li><p>编译 linux 32 gpu 的产物<br><code>cargo build --release --target i686-unknown-linux-gnu</code></p>
</li>
</ul>
<span id="more"></span>

<h3 id="2-2-问题"><a href="#2-2-问题" class="headerlink" title="2.2 问题"></a>2.2 问题</h3><p>以上编译产物是非静态的二进制，运行时会对动态环境有依赖，如依赖 libc.so、依赖 libssl.so 等，以下是对某个 rust 编写的 agent 使用 <code>x86_64-unknown-linux-gnu</code> 编译产物的依赖：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ldd agent</span><br><span class="line">        linux-vdso.so.1 =&gt;  (0x00007fffa0b6f000)</span><br><span class="line">        /$LIB/libonion.so =&gt; /lib64/libonion.so (0x00007f6ce530f000)</span><br><span class="line">        libgcc_s.so.1 =&gt; /lib64/libgcc_s.so.1 (0x00007f6ce3819000)</span><br><span class="line">        librt.so.1 =&gt; /lib64/librt.so.1 (0x00007f6ce3611000)</span><br><span class="line">        libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f6ce33f5000)</span><br><span class="line">        libm.so.6 =&gt; /lib64/libm.so.6 (0x00007f6ce30f3000)</span><br><span class="line">        libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f6ce2eef000)</span><br><span class="line">        libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f6ce2b21000)</span><br><span class="line">        /lib64/ld-linux-x86-64.so.2 (0x00007f6ce51f6000)</span><br></pre></td></tr></table></figure>

<p>而对于在运行客户环境的 agent，要尽量减少外部的依赖，因此 agent 需要编译为纯静态的二进制， 即编译target 为 <code>x86_64-unknown-linux-musl</code>, 此时使用 cargo 进行编译就不方便了。</p>
<p>如果使用 musl 的方式编译，需要依赖 musl libc 和 musl-gcc。<br>参考： <a href="https://rustwiki.org/zh-CN/edition-guide/rust-2018/platform-and-target-support/musl-support-for-fully-static-binaries.html#musl-%E6%94%AF%E6%8C%81%E5%AE%8C%E5%85%A8%E9%9D%99%E6%80%81%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6">https://rustwiki.org/zh-CN/edition-guide/rust-2018/platform-and-target-support/musl-support-for-fully-static-binaries.html#musl-%E6%94%AF%E6%8C%81%E5%AE%8C%E5%85%A8%E9%9D%99%E6%80%81%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6</a></p>
<p>如果要支持多平台的产物编译，除了要安装对应的musl target，还需要各个平台的 musl libc 和 musl-gcc 版本，搭建跨平台编译环境就很不方便了。</p>
<h2 id="3-cross-进行跨平台编译"><a href="#3-cross-进行跨平台编译" class="headerlink" title="3. cross 进行跨平台编译"></a>3. cross 进行跨平台编译</h2><p>于是 <code>cross</code> 就应运而生了，它通过容器技术屏蔽了各个环境编译依赖的细节，实现了 <code>0</code> 配置的跨平台编译体验，而且保持了同 cargo 一致的体验。</p>
<p>演示如下：</p>
<h3 id="3-1-安装-cross"><a href="#3-1-安装-cross" class="headerlink" title="3.1 安装 cross"></a>3.1 安装 cross</h3><p><code>crago install cross</code><br>之后就可以使用 <code>cross</code> 替换到 <code>cargo</code> 命令了。</p>
<h3 id="3-2-编译-x86-64-unknown-linux-musl"><a href="#3-2-编译-x86-64-unknown-linux-musl" class="headerlink" title="3.2 编译 x86_64-unknown-linux-musl"></a>3.2 编译 <code>x86_64-unknown-linux-musl</code></h3><p><code>cross build --release --target x86_64-unknown-linux-musl</code></p>
<p>cross 会根据 target 拉取对应的容器镜像，然后在容器镜像内部进行编译， 编译的产物也会挂载在本机的 <code>target/x86_64-unknown-linux-musl</code> 目录下。</p>
<p>有了 <code>cross</code>，就不用再纠结于各个 target 的复杂依赖，可以很清爽的进行跨平台编译了。</p>
<h2 id="4-cross-实现原理"><a href="#4-cross-实现原理" class="headerlink" title="4. cross 实现原理"></a>4. cross 实现原理</h2><p>那么 <code>cross</code> 是如何实现的呢？<br>主要有两点：</p>
<ul>
<li>使用容器镜像屏蔽了各平台的依赖细节</li>
<li>内部调用 <code>cargo</code> 保证了 cross 与 cargo 命令完全一致的使用体验<h3 id="4-1-使用容器镜像屏蔽了各平台的依赖细节"><a href="#4-1-使用容器镜像屏蔽了各平台的依赖细节" class="headerlink" title="4.1 使用容器镜像屏蔽了各平台的依赖细节"></a>4.1 使用容器镜像屏蔽了各平台的依赖细节</h3>以 <code>target/x86_64-unknown-linux-musl</code> 为例， 执行 cross build 时，cross 会拉取该 target 对应的镜像，并在镜像中执行 cargo build 的命令，该 target 的镜像的 dockerfile 里封装了依赖的细节。</li>
</ul>
<p>Dockerfile.x86_64-unknown-linux-musl</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 基础镜像</span><br><span class="line">FROM ubuntu:20.04</span><br><span class="line"></span><br><span class="line"># 安装基本的lib，如 gcc、make git 等</span><br><span class="line">COPY common.sh lib.sh /</span><br><span class="line">RUN /common.sh</span><br><span class="line"></span><br><span class="line"># 安装 cmake</span><br><span class="line">COPY cmake.sh /</span><br><span class="line">RUN /cmake.sh</span><br><span class="line"></span><br><span class="line"># 安装 xargo</span><br><span class="line">COPY xargo.sh /</span><br><span class="line">RUN /xargo.sh</span><br><span class="line"></span><br><span class="line"># 编译 musl-gcc</span><br><span class="line">COPY musl.sh /</span><br><span class="line">RUN /musl.sh TARGET=x86_64-linux-musl</span><br><span class="line"></span><br><span class="line"># 设置 target 和 链接器</span><br><span class="line">ENV CARGO_TARGET_X86_64_UNKNOWN_LINUX_MUSL_LINKER=x86_64-linux-musl-gcc \</span><br><span class="line">    CC_x86_64_unknown_linux_musl=x86_64-linux-musl-gcc \</span><br><span class="line">    CXX_x86_64_unknown_linux_musl=x86_64-linux-musl-g++</span><br></pre></td></tr></table></figure>

<p>感兴趣的可以看下各脚本的实现细节：<br><a href="https://github.com/rust-embedded/cross/blob/master/docker/Dockerfile.x86_64-unknown-linux-musl">dockerfile 地址</a></p>
<h3 id="4-2-内部调用-cargo-保证了-cross-与-cargo-命令完全一致的使用体验"><a href="#4-2-内部调用-cargo-保证了-cross-与-cargo-命令完全一致的使用体验" class="headerlink" title="4.2 内部调用 cargo 保证了 cross 与 cargo 命令完全一致的使用体验"></a>4.2 内部调用 <code>cargo</code> 保证了 cross 与 cargo 命令完全一致的使用体验</h3><p>cross 内部在起来对应target 的容器后，内部调用 cargo 以达到同 cargo 的一致体验。参考：<br><a href="https://github.com/rust-embedded/cross/blob/2b2a01220c73ae517129019d436d382412d1928b/src/main.rs#L389">调用代码</a></p>
<h2 id="5-结语"><a href="#5-结语" class="headerlink" title="5. 结语"></a>5. 结语</h2><p><code>cross</code> 作为一款 <code>0</code> 配置的 Rust 跨平台编译利器，极大地便捷了日常开发和测试、流水线跨平台和发布等工作，<br>此外 cross 也支持 target 自定义镜像，方便用户将自定义的静态链接库等很方便地集成进去。 </p>
]]></content>
      <categories>
        <category>rust</category>
      </categories>
      <tags>
        <tag>rust</tag>
        <tag>cross</tag>
        <tag>跨平台编译</tag>
      </tags>
  </entry>
  <entry>
    <title>docker实战：原理篇</title>
    <url>/posts/6d66e529/</url>
    <content><![CDATA[<h2 id="容器的本质：特殊的进程"><a href="#容器的本质：特殊的进程" class="headerlink" title="容器的本质：特殊的进程"></a>容器的本质：特殊的进程</h2><p>进程是程序和其运行所需要的计算机环境的总和，是计算机进行资源分配和调度的独立单位。 而容器则是一种特殊的进程，它被内核隔离在独立的命名空间下，享有独立的网络、磁盘、文件系统，并且被限制了执行所需要的资源（如cpu 内存等）。</p>
<p>容器同宿主机上其他进程一样， 同其他进程共享宿主机的内核，并接受内核的调度。</p>
<p>容器与虚拟机的区别，如下图所示：</p>
<img src="/images/vm_and_container.png">

<p>图左画出了虚拟机的工作原理。Hypervisor通过硬件虚拟化功能，模拟出了运行一个操作系统需要的各种硬件，比如 CPU、内存、I/O 设备等等。然后，它在这些虚拟的硬件上安装了一个新的操作系统，即 Guest OS。</p>
<p>图右中并不存在一个Hypervisor层模拟各个硬件，它仅仅只是对容器进程的运行环境进行了限制，但仍然使用了宿主机的内核。</p>
<p>因此此图描述的不够严谨，系统中不存在真实运行的各个容器进程，这只不过是障眼法。</p>
<p>更严谨的应该如下图：</p>
<img src="/images/vm_and_container_new.jpg">
此图中，容器进程直接运行在宿主机上，被宿主机内核管理，docker仅仅起到旁路辅助和管理工作。

<span id="more"></span>

<h2 id="隔离和限制：Namespace和Cgroup"><a href="#隔离和限制：Namespace和Cgroup" class="headerlink" title="隔离和限制：Namespace和Cgroup"></a>隔离和限制：Namespace和Cgroup</h2><h3 id="隔离"><a href="#隔离" class="headerlink" title="隔离"></a>隔离</h3><p>docker使用 Linux Namespace将容器进程进行隔离，容器享有独立的进程空间，因此在容器内部使用<code>ps</code>查看，会发现运行的进程id为1，而宿主机的其他资源不再可见。</p>
<p>docker 使用linux内核提供的namespace进行隔离，相比虚拟机，拥有着<code>启动速度快</code>和<code>高性能</code>的优点。</p>
<p>但也有其缺点，那就是隔离的不够彻底，有如下问题：</p>
<ol>
<li>由于共享内核，无法在window宿主机上运行linux容器、或者在低版本linux宿主机上运行高版本linux容器</li>
<li>某些资源是全局资源，无法被namespace， 如时间。 若在一个容器内对时间进行修改， 则其他容器及宿主机其他进程也会生效。</li>
</ol>
<h3 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h3><p>docker使用Linux Cgroup对容器进程进行资源限制，限制的资源包括：cpu、内存、磁盘、网络带宽等。</p>
<p>因为容器也是进程，只有对容器进行资源限制，才能避免容器占用过多宿主机资源，从而影响其他容器、宿主机其他进程的正常工作。</p>
<h2 id="容器镜像原理：rootfs"><a href="#容器镜像原理：rootfs" class="headerlink" title="容器镜像原理：rootfs"></a>容器镜像原理：rootfs</h2><p>通过上面的描述，我们可以对容器有一个准确的定义：容器是一种使用namespace和cgroup进行隔离和限制的进程。</p>
<p>那容器内访问的文件系统是如何工作的呢？</p>
<p>答： 通过Mount Namespace将文件系统挂载为容器进程的根文件系统。</p>
<p>docker 运行的核心原理如下：</p>
<ol>
<li>启用 Linux Namespace配置</li>
<li>设置指定的Cgroup</li>
<li>切换进程的根目录。</li>
</ol>
<p>需要注意的是ootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。</p>
<p>正是由于 rootfs 的存在，容器才有了一个杀手锏： 一致性。</p>
<p>容器本质是进程，进程的本质是程序及其运行环境的组合，这里的运行环境不单单只java版本、类库版本等，还包括操作系统版本等。</p>
<p>而rootfs将除linux内核外所有依赖环境进行打包，从而保证了软件开发、测试、部署、交付全流程的一致性。也因此docker改变了软件开发和交付的流程。</p>
]]></content>
      <categories>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>that_is_me_on_github: 一个统计github contribution的小工具</title>
    <url>/posts/8499e970/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>linus曾说过： “talk is cheap, show me the code”， 一个人的代码能在一定程度上代表他的技术水平，而参与开源项目，既能从中学习并提升自己，又可以在github上留下自己的足迹，供后人凭吊。</p>
<p>而且在知识付费盛行的今天，如何评判一个大佬是否真的在开源社区呼风唤雨，还是徒有虚名，仅仅改了个注释就以contributor自居。统计他的贡献，也能让我们擦亮眼睛，避免盲从被收了智商税。</p>
<h2 id="that-is-me-on-github"><a href="#that-is-me-on-github" class="headerlink" title="that_is_me_on_github"></a>that_is_me_on_github</h2><p>这是一个python实现的cli， 用于统计某个username的github贡献信息，并生成markdown文档。 生成的Markdown中包含该用户的owned repos,  followers, prs 和issues，比较能够全面地分析该用户的贡献。</p>
<p><a href="https://github.com/hustclf/that_is_me_on_github">项目地址</a><br><a href="https://github.com/hustclf/that_is_me_on_github/blob/master/demo.md">demo</a></p>
<span id="more"></span>

<h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><p>我开发这个小工具有以下两个初衷。</p>
<ol>
<li><p>我希望在博客上添加一个<a href="https://chenlifei.tech/contributions/">社区贡献</a>页，用来展示我参与的社区贡献，为博客吸引些人气。</p>
</li>
<li><p>我希望尝试走一个完整开源项目从立项、开发、发布、维护的流程。麻雀虽小、五脏俱全，正好可以通过这个小工具实践下自己的一些想法。</p>
</li>
</ol>
<h2 id="项目开发及发布"><a href="#项目开发及发布" class="headerlink" title="项目开发及发布"></a>项目开发及发布</h2><h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>实现一个cli，能够根据提供的github username, 爬取其参与的所有开源项目，并生成markdown。</p>
<h3 id="项目管理"><a href="#项目管理" class="headerlink" title="项目管理"></a>项目管理</h3><ul>
<li>使用github issues进行issue tracking。</li>
<li>使用github project进行版本管理及迭代（类似jira）</li>
<li>使用slack stackoverflow email进行使用交流</li>
</ul>
<h3 id="开发框架"><a href="#开发框架" class="headerlink" title="开发框架"></a>开发框架</h3><ul>
<li>使用pipenv进行开发</li>
<li>github提供了api来获取信息，pygithub是对api进行二次封装的python client。</li>
<li>click是开发python cli的标准框架。通过它可以快速地开发python cli。</li>
</ul>
<h3 id="测试框架"><a href="#测试框架" class="headerlink" title="测试框架"></a>测试框架</h3><ul>
<li>使用pytest进行单元测试及集成测试。</li>
</ul>
<h3 id="持续集成"><a href="#持续集成" class="headerlink" title="持续集成"></a>持续集成</h3><ul>
<li>使用circleci进行持续集成。</li>
</ul>
<h3 id="代码覆盖"><a href="#代码覆盖" class="headerlink" title="代码覆盖"></a>代码覆盖</h3><ul>
<li>使用codecov进行代码覆盖率统计。</li>
</ul>
<h3 id="发布"><a href="#发布" class="headerlink" title="发布"></a>发布</h3><ul>
<li>pypi包发布：<a href="https://pypi.org/project/that-is-me-on-github/">https://pypi.org/project/that-is-me-on-github/</a></li>
<li>docker发布：<a href="https://hub.docker.com/r/hustclf/that_is_me_on_github">https://hub.docker.com/r/hustclf/that_is_me_on_github</a></li>
</ul>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>还在活跃开发中。</p>
]]></content>
      <categories>
        <category>社区贡献</category>
      </categories>
      <tags>
        <tag>that_is_me_on_github</tag>
      </tags>
  </entry>
  <entry>
    <title>使用operator在kubernetes上部署spark</title>
    <url>/posts/320cc8d6/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Spark是大数据领域极为流行的处理引擎，它拥有丰富的套件和活跃的社区生态，其结合pyspark极大地提升了数据工程师理解和分析数据的生产力。</p>
<p>Kubernetes是近几年最火的开源项目之一，在经历2018年的快速发展后，kubernetes已经成为容器编排领域的事实标准。 在充分地支持了无状态服务之后，开源社区开始努力解决复杂有状态服务的容器编排，为此提出了operator的概念，用于解决复杂有状态服务的编排。 kubernetes将会全面支持大数据领域的资源编排和管理。</p>
<p>Spark在2.3.0版本支持了kubernetes作为原生集群runtime的功能，相关的讨论在<a href="https://issues.apache.org/jira/browse/SPARK-18278">SPARK-18278</a></p>
<p>本文主要基于谷歌云的spark-on-k8s-operator项目，实践在kubernetes集群使用operator部署spark，并运行pyspark demo job。</p>
<span id="more"></span>

<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ol>
<li>kubernetes集群</li>
<li>helm and tiller</li>
<li>git</li>
<li>spark镜像 （谷歌的镜像国内无法访问）</li>
</ol>
<h3 id="版本说明"><a href="#版本说明" class="headerlink" title="版本说明"></a>版本说明</h3><p>kubernetes 1.14.0<br>spark 2.4.0</p>
<h2 id="使用helm安装spark-operator"><a href="#使用helm安装spark-operator" class="headerlink" title="使用helm安装spark operator"></a>使用helm安装spark operator</h2><ol>
<li><p>下载charts</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> git <span class="built_in">clone</span> https://github.com/helm/charts.git</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>install spark operator</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> helm install --name=spark incubator/sparkoperator --namespace spark-operator --<span class="built_in">set</span> sparkJobNamespace=spark-jobs --<span class="built_in">set</span> serviceAccounts.spark.name=spark</span></span><br></pre></td></tr></table></figure>
<p>该命令将会在<code>spark-operator</code>命名空间下运行一个operator pod， 并且会监听<code>spark-jobs</code>命名空间下提交的spark job。</p>
</li>
</ol>
<h2 id="运行pyspark-pi"><a href="#运行pyspark-pi" class="headerlink" title="运行pyspark-pi"></a>运行pyspark-pi</h2><ol>
<li><p>下载spark-on-k8s-operator</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> git <span class="built_in">clone</span> https://github.com/GoogleCloudPlatform/spark-on-k8s-operator.git</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>运行pyspark-pi</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># kubectl apply -f examples/spark-py-pi.yaml</span><br></pre></td></tr></table></figure>
<p>注意： 由于设定的spark job的namspace为<code>spark-jobs</code>，因此需要将spark-py-pi.yaml由<code>default</code>改为<code>spark-jobs</code>。</p>
</li>
</ol>
<h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><h3 id="Design"><a href="#Design" class="headerlink" title="Design"></a>Design</h3><h3 id="交流"><a href="#交流" class="headerlink" title="交流"></a>交流</h3><p>在slack上有spark-operator相关的channel，可用于交流及答疑<br><a href="https://kubernetes.slack.com/messages/CALBDHMTL">Slack</a></p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://issues.apache.org/jira/browse/SPARK-18278">spark 2.3.0开始支持kubernetes</a><br><a href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator">spark-on-k8s-operator github repo</a><br><a href="https://github.com/helm/charts/tree/master/incubator/sparkoperator">spark operator chart repo</a></p>
]]></content>
      <categories>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>operator</tag>
        <tag>spark</tag>
        <tag>helm</tag>
      </tags>
  </entry>
  <entry>
    <title>为flink-deployer添加cancel job feature</title>
    <url>/posts/ebbd7fcc/</url>
    <content><![CDATA[<h1 id="为flink-deployer添加cancel-job-feature"><a href="#为flink-deployer添加cancel-job-feature" class="headerlink" title="为flink-deployer添加cancel job feature"></a>为flink-deployer添加cancel job feature</h1><p>kafkacat是一款go实现的用于部署flink jobs的cli, 它内部集成了flink rest api, 支持对flink job的部署，更新等。</p>
<p>目前支持的功能有：</p>
<ul>
<li>Listing jobs</li>
<li>Deploying a new job</li>
<li>Updating an existing job</li>
<li>Querying Flink queryable state</li>
</ul>
<p>我也在使用flink-deployer，用于集成ci/cd pipeline中，支持自动部署flink job到kubernetes集群。 但日常开发中，有时候会用到取消job的功能，但目前flink-deployer还不支持，但维护者<a href="https://github.com/ing-bank/flink-deployer/issues/26">支持其他contributor贡献该特性</a>，因此我<br>打算贡献该特性，顺便实战入门下golang。</p>
<span id="more"></span>

<h2 id="调研flink-rest-api"><a href="#调研flink-rest-api" class="headerlink" title="调研flink rest api"></a>调研flink rest api</h2><p>flink rest api中提供了terminate flink job的api（ [链接]<br>(<a href="https://ci.apache.org/projects/flink/flink-docs-stable/monitoring/rest_api.html#jobs-jobid-1">https://ci.apache.org/projects/flink/flink-docs-stable/monitoring/rest_api.html#jobs-jobid-1</a>) ）, 并且支持两种取消job的模式：</p>
<ul>
<li><p>cancel</p>
</li>
<li><p>stop</p>
</li>
</ul>
<p>两种模式中，相比cancel， stop更加柔和些，相关比较(<a href="https://ci.apache.org/projects/flink/flink-docs-stable/ops/cli.html">参考</a>)。</p>
<h2 id="pr地址"><a href="#pr地址" class="headerlink" title="pr地址"></a>pr地址</h2><p><a href="https://github.com/ing-bank/flink-deployer/pull/37">pr</a></p>
]]></content>
      <categories>
        <category>社区贡献</category>
      </categories>
      <tags>
        <tag>flink</tag>
        <tag>flink-deployer</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo NexT主题集成disqus评论系统</title>
    <url>/posts/8838407/</url>
    <content><![CDATA[<h1 id="hexo-NexT主题集成disqus评论系统"><a href="#hexo-NexT主题集成disqus评论系统" class="headerlink" title="hexo NexT主题集成disqus评论系统"></a>hexo NexT主题集成disqus评论系统</h1><h2 id="为何需要评论系统"><a href="#为何需要评论系统" class="headerlink" title="为何需要评论系统"></a>为何需要评论系统</h2><p>一个良好的博客系统，绝不仅仅是个人的琐碎日记本，把自己只言片语的感悟或者一知半解的知识散播到互联网上，这是很不负责的行为。 因为你的博文会被很多同领域的同学看到，如果博文的观点是错的，那将以讹传讹，不仅无丝毫借鉴意义，反而浪费他人的宝贵时间。那如何发现自己博文的不足甚至谬误呢？  一个良好的评论系统能帮到你。</p>
<span id="more"></span>

<h2 id="评论系统的作用"><a href="#评论系统的作用" class="headerlink" title="评论系统的作用"></a>评论系统的作用</h2><ul>
<li>广交朋友，多多交流</li>
<li>改进博文写作水平，修正错误的观点</li>
<li>正反馈作者，提升写作热情</li>
</ul>
<h2 id="评论系统选择"><a href="#评论系统选择" class="headerlink" title="评论系统选择"></a>评论系统选择</h2><p>NexT主题提供了许多第三方评论系统的集成<a href="https://theme-next.iissnan.com/third-party-services.html">参考</a>，大致有如下几种：</p>
<ul>
<li>disqus</li>
<li>Facebook Comments：国内技术同学多数没有Facebook的账号，不方便，pass</li>
<li>HyperComments: 不太清楚</li>
<li>多说：不再维护</li>
<li>网易云跟帖： 不再维护</li>
<li>gitment、gitalk: 调研github api, 以issue和comment的方式comment, 慎用</li>
<li>Valine： 过于简单</li>
</ul>
<p>我个人对评论系统的要求如下：</p>
<ul>
<li>集成简单</li>
<li>评论内容不能丢</li>
<li>支持邮件提醒，以便能及时回复</li>
</ul>
<p>经过多次踩坑，我最终选择了disqus作为评论系统，disqus能支持目前我需要的所有功能，并且还有较强大的统计功能（目前用不到)。</p>
<p>有些同学会担心disqus会被墙掉，但目前我的使用而言，没有发现被墙的情况。而且即使被墙了，我觉得也无所谓，不会翻墙的技术同学也不在我的博客受众范围内。</p>
<h2 id="如何集成disqus"><a href="#如何集成disqus" class="headerlink" title="如何集成disqus"></a>如何集成disqus</h2><h3 id="注册"><a href="#注册" class="headerlink" title="注册"></a><a href="https://disqus.com/profile/signup/">注册</a></h3><img src="/images/disqus/signup.png">

<h3 id="登陆，点击-GET-STARTED-开始创建站点，之后就可以点击右上角的-Admin-进入后台管理。"><a href="#登陆，点击-GET-STARTED-开始创建站点，之后就可以点击右上角的-Admin-进入后台管理。" class="headerlink" title="登陆，点击 GET STARTED 开始创建站点，之后就可以点击右上角的 Admin 进入后台管理。"></a>登陆，点击 <code>GET STARTED</code> 开始创建站点，之后就可以点击右上角的 Admin 进入后台管理。</h3><img src="/images/disqus/login.png">

<h3 id="点击-I-want-to-install-Disqus-on-my-site"><a href="#点击-I-want-to-install-Disqus-on-my-site" class="headerlink" title="点击 I want to install Disqus on my site"></a>点击 <code>I want to install Disqus on my site</code></h3><img src="/images/disqus/disqus_intent.png">

<h3 id="按照表单填写信息，记住-Website-Name-这条属性。"><a href="#按照表单填写信息，记住-Website-Name-这条属性。" class="headerlink" title="按照表单填写信息，记住 Website Name 这条属性。"></a>按照表单填写信息，记住 Website Name 这条属性。</h3><img src="/images/disqus/create.png">

<h3 id="接下来按照指引填写信息，完成第三步-3-Configure-Disqus-后点击最下面-Complete-Setup-完成创建。【中间会有一个嵌入代码的案例，不是-Next-主题的可以参考下】"><a href="#接下来按照指引填写信息，完成第三步-3-Configure-Disqus-后点击最下面-Complete-Setup-完成创建。【中间会有一个嵌入代码的案例，不是-Next-主题的可以参考下】" class="headerlink" title="接下来按照指引填写信息，完成第三步 3.Configure Disqus 后点击最下面 Complete Setup 完成创建。【中间会有一个嵌入代码的案例，不是 Next 主题的可以参考下】"></a>接下来按照指引填写信息，完成第三步 3.Configure Disqus 后点击最下面 Complete Setup 完成创建。【中间会有一个嵌入代码的案例，不是 Next 主题的可以参考下】</h3><img src="/images/disqus/settings.png">

<h3 id="接下来配置主题下面的-config-yml-文件。"><a href="#接下来配置主题下面的-config-yml-文件。" class="headerlink" title="接下来配置主题下面的 config.yml 文件。"></a>接下来配置主题下面的 config.yml 文件。</h3><p>大于等于5.1.1版本，将 disqus 下的 enable 设定为 true，同时提供 shortname。 count 用于指定是否显示评论数量。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">disqus:</span><br><span class="line">  enable: true</span><br><span class="line">  shortname:</span><br><span class="line">  count: true</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>小于5.1.1 版本，设定 disqus_shortname 的值即可。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">disqus_shortname: shortname</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
        <tag>评论系统</tag>
      </tags>
  </entry>
  <entry>
    <title>使用logstash将kafka数据写入elasticsearch</title>
    <url>/posts/aaa3e6e1/</url>
    <content><![CDATA[<hr>
<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>将kafka中的日志写入elasticsearch，并要求支持以下功能：</p>
<ol>
<li>根据日志时间建立index，便于后续对index的管理</li>
<li>使用log_id作为document_id，保持写入es的幂等性</li>
<li>对建立的多个index, 设置相同的alias （业务方使用alias进行query，对具体index不感知）</li>
<li>由于日志时间为epoch_seconds，无法被es自动引用为时间，需要进行字段mapping</li>
</ol>
<h2 id="软件版本及日志格式"><a href="#软件版本及日志格式" class="headerlink" title="软件版本及日志格式"></a>软件版本及日志格式</h2><h4 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h4><p>kafka: 2.1.0</p>
<p>elasticsearch: 6.6.0</p>
<p>kakfa-connect-elasticsearch: v5.1.1</p>
<p>logstash: 6.6.0</p>
<span id="more"></span>

<h4 id="日志格式"><a href="#日志格式" class="headerlink" title="日志格式"></a>日志格式</h4><p>日志是以json格式存储在topic中，topic_name为logs</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">	&quot;log_id&quot;: &#x27;log_xxxxxxx&#x27;,</span><br><span class="line">	&quot;timestamp&quot;: 1550167937,</span><br><span class="line">	&quot;user_id&quot;: &quot;xxxx&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="计算方案选型"><a href="#计算方案选型" class="headerlink" title="计算方案选型"></a>计算方案选型</h2><h3 id="kafka-connect-elasticsearch"><a href="#kafka-connect-elasticsearch" class="headerlink" title="kafka-connect-elasticsearch"></a>kafka-connect-elasticsearch</h3><p>kafka-connect-elasticseach是confluent（kafka团队的母公司）提供的kafka connect的一个plugin， 用于将kakfa的数据导入es</p>
<p>相关地址及参考链接如下：</p>
<p><a href="https://github.com/confluentinc/kafka-connect-elasticsearch">github repo</a></p>
<p><a href="https://docs.confluent.io/current/connect/kafka-connect-elasticsearch/index.html">document</a></p>
<h3 id="logstash"><a href="#logstash" class="headerlink" title="logstash"></a>logstash</h3><p>logstash 提供kafka input plugin 和 elasticsearch output plugin, 也支持将kafka数据导入es</p>
<p><a href="https://www.elastic.co/guide/en/logstash/current/index.html">document</a></p>
<h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><p>kafka-connect-elasticsearch是基于kafka connect api实现的plugin，功能强在kafka端，目前该插件对elasticsearch的支持有限，而且迭代也较慢，而且目前部署对devops也不友好，不满足我们需要的功能</p>
<p>logstash是elasticsearch较早推出的收集及分发数据的组件，功能强在elasticsearch端，功能强大且较成熟，并且支持所需的所有功能。</p>
<p>因此，决定使用logstash来满足我们的需求</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="任务分拆"><a href="#任务分拆" class="headerlink" title="任务分拆"></a>任务分拆</h3><ol>
<li>支持按照日志创建index名称： 在output中指定index的命名方式</li>
<li>支持使用log_id作为es的document_id</li>
<li>支持设置别名</li>
<li>支持将日志时间戳mapping 为document的时间戳</li>
</ol>
<p>要实现上述目标，只需要提供两个配置文件：</p>
<p>1 pipeline.yaml: 用于定义input fliter output等信息</p>
<p>2 index-template.json: 用于定义index模板，将index名与alias动态关联，并且创建mapping</p>
<h3 id="pipeline-yaml"><a href="#pipeline-yaml" class="headerlink" title="pipeline.yaml"></a>pipeline.yaml</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># configuration for transformming events from kafka to elasicsearch</span><br><span class="line"># Kafka -&gt; Logstash -&gt; Elasticsearch pipeline.</span><br><span class="line">input &#123;</span><br><span class="line">  kafka &#123;</span><br><span class="line">    bootstrap_servers =&gt; “localhost:9092&quot;</span><br><span class="line">    topics =&gt; [&quot;logs&quot;]</span><br><span class="line">    group_id =&gt; &quot;logstash-logs&quot;</span><br><span class="line">    auto_offset_reset =&gt; &quot;earliest&quot;</span><br><span class="line">    codec =&gt; json</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">  date &#123;</span><br><span class="line">    match =&gt; [&quot;timestamp&quot;, &quot;UNIX&quot;]</span><br><span class="line">    target =&gt; &quot;@timestamp&quot;</span><br><span class="line">    timezone =&gt; &quot;Asia/Shanghai&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; [&quot;localhost:9200&quot;]</span><br><span class="line">    index =&gt; &quot;logs-%&#123;+YYYY.MM&#125;&quot;</span><br><span class="line">    document_type =&gt; &quot;log&quot;</span><br><span class="line">    document_id =&gt; &quot;%&#123;log_id&#125;&quot;</span><br><span class="line">    template =&gt; &quot;conf/index-template.json&quot;</span><br><span class="line">    template_name =&gt; &quot;logs&quot;</span><br><span class="line">    template_overwrite =&gt; true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>解释：</p>
<ul>
<li>input: 配置了kafka相关的信息</li>
<li>fliter: 由于index命名时所用的时间为logstash的元数据 <code>@timestamp</code>, 因此需要在<code>fliter</code>中使用<code>date</code> 插件，用日志时间覆写原始的<code>@timestamp</code> （原始的<code>@timestamp</code>是日志摄入时间，而非日志时间）</li>
<li>output: 配置了elasticsearch的信息，以及使用log_id作为document_id， index的命名、及index使用的模板路径<code>config/index-template.json</code></li>
</ul>
<h3 id="index-template-json"><a href="#index-template-json" class="headerlink" title="index-template.json"></a>index-template.json</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;index_patterns&quot; : [&quot;logs-*&quot;],</span><br><span class="line">    &quot;settings&quot;: &#123;</span><br><span class="line">         &quot;number_of_shards&quot;: 1,</span><br><span class="line">     &#125;,</span><br><span class="line">     &quot;mappings&quot;: &#123;</span><br><span class="line">         &quot;log&quot;: &#123;</span><br><span class="line">             &quot;properties&quot;: &#123;</span><br><span class="line">                 &quot;timestamp&quot;: &#123;</span><br><span class="line">                     &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">                     &quot;format&quot;: &quot;epoch_second&quot;</span><br><span class="line">                 &#125;,</span><br><span class="line">             &#125;,</span><br><span class="line">             &quot;dynamic_date_formats&quot;: [</span><br><span class="line">                 &quot;date_time&quot;,</span><br><span class="line">                 &quot;date_time_no_millis&quot;</span><br><span class="line">             ]</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;,</span><br><span class="line">    &quot;aliases&quot; : &#123;</span><br><span class="line">        &quot;logs&quot; : &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>解释：</p>
<ul>
<li>index_patterns: 确定了该index模板作用的index范围</li>
<li>mappings: 配置使用日志的<code>timestamp</code>字段，作为es中document的日期字段</li>
<li>alias: 为新增的index，创建统一的别名</li>
</ul>
<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>下载logstash（current version = 6.6.0）, 并将上述两个文件置于<code>path/config</code>目录下, 然后运行如下命令:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ bin/logstash -f config/pipeline.yaml</span><br></pre></td></tr></table></figure>

<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>logstash已经提供了官方镜像， 因此可以使用docker-compose或者kubernetes来部署logstash，此处不再赘述</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>logstash</tag>
        <tag>kafka</tag>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>修复kafkacat json format的bug</title>
    <url>/posts/66a1e560/</url>
    <content><![CDATA[<h1 id="修复kafkacat-json-format的bug"><a href="#修复kafkacat-json-format的bug" class="headerlink" title="修复kafkacat json format的bug"></a>修复kafkacat json format的bug</h1><p>kafkacat是一款c语言实现的kafka client cli, 不同于kafka官方包里的cli，使用比较繁琐，并且依赖jvm才能运行， kafkacat是一个小巧的cmd， 依赖一个基础c library: <a href="https://github.com/edenhill/librdkafka">librdkafka</a>,能够很方便地对kafka进行一些基本操作，如list、producer、consumer等。</p>
<span id="more"></span>

<p>kafkacat的作者是<a href="https://github.com/edenhill">edenhill</a>， 同时也是librdkafka的作者，现在应该是kafka的母公司，confluent的一名工程师</p>
<h2 id="如何发现该bug？"><a href="#如何发现该bug？" class="headerlink" title="如何发现该bug？"></a>如何发现该bug？</h2><p>kafka在v0.10之后的版本，每条数据除了key 和message之外，还会携带一条timestamp， 代表该条日志的时间.( <a href="https://stackoverflow.com/questions/39514167/retrieve-timestamp-based-data-from-kafka">参考</a> )</p>
<p>我在使用kafka streams开发应用时，发现我的输出的topic总是会被kafka清理掉， 我产生的日志使用event timestamp作为执行的timestamp，数据是1月以前的，因此我怀疑输出的topic的日志，timestamp使用的是event timestamp，因此被kafka认为是过期日志，清理掉了。</p>
<p>kafkacat是支持消费时指定固定的格式的，通过指定 <code>-J</code> 参数，可以打印json格式的message,其中会携带该message的所有源数据，包括： partition, key, value, timestamp等。</p>
<p>因此我使用kafkacat进行消费时，发现了该bug， 按照json格式消费时，展示timestamp字段不正确，因此我提了相关issue， 并通过阅读源码，修改了该bug。</p>
<h2 id="issue地址"><a href="#issue地址" class="headerlink" title="issue地址"></a>issue地址</h2><p><a href="https://github.com/edenhill/kafkacat/issues/167">issue</a></p>
<h2 id="pr地址"><a href="#pr地址" class="headerlink" title="pr地址"></a>pr地址</h2><p><a href="https://github.com/edenhill/kafkacat/pull/166">pr</a></p>
]]></content>
      <categories>
        <category>社区贡献</category>
      </categories>
      <tags>
        <tag>kafkacat</tag>
      </tags>
  </entry>
  <entry>
    <title>git branch模型最佳实践[译]</title>
    <url>/posts/c1cadd8e/</url>
    <content><![CDATA[<hr>
<p>【原文链接】：<br><a href="http://nvie.com/posts/a-successful-git-branching-model/">A successful Git branching model</a></p>
<hr>
<h2 id="git-branch大图"><a href="#git-branch大图" class="headerlink" title="git branch大图"></a>git branch大图</h2><p>下图是git branch 模型的全景图，可以先阅读后续章节，最后再回头查看</p>
<img src="/images/gitflow.png">

<span id="more"></span>

<h2 id="为什么使用git"><a href="#为什么使用git" class="headerlink" title="为什么使用git"></a>为什么使用git</h2><p>网上已经有很多关于git与集中代码控制软件的讨论，彻底的比较可以参考<a href="https://git.wiki.kernel.org/index.php/GitSvnComparsion">这里</a>。作为一个开发者，相比其他代码管理软件，我更倾向于使用git。git彻底地改变了我们对于分支和合并的概念的认识。用过csv/Subersion的人都清楚，分支和合并的工作是很巨大的，而且会花费很长时间。</p>
<p>但对于git而言，分支和合并是极其简单和快速的，他们已经成为开发者日常工作流的一部分。因此分支和合并不再为开发者惧怕。</p>
<p>接下来，我们将讨论git的开发模型。为了能让软件开发流程更加合理， 每个团队成员都应该遵守这个模型提供的开发流程。</p>
<h2 id="git是分布式的又是集中的"><a href="#git是分布式的又是集中的" class="headerlink" title="git是分布式的又是集中的"></a>git是分布式的又是集中的</h2><p>我们一般会在github或者git服务器上建立一个远程库，这个库被认为是中心库（与svn等不同，git是分布式的，技术层面上不存在中心库, 我们把中心库命名为origin， 大家对这都很熟悉</p>
<img src="http://nvie.com/img/centr-decentr@2x.png">

<p>开发者从origin pull代码，并将代码push到origin。因为git是分布式的，每个人除了从origin来push和pull代码， 每个人也可以从对方那push或者pull代码。如图所示， alice david bob clair之间也可以互相pull push代码</p>
<h2 id="主要分支"><a href="#主要分支" class="headerlink" title="主要分支"></a>主要分支</h2><p>一般而言，每个项目开发中都会有如下两个始终存在的分支：</p>
<ul>
<li>master</li>
<li>develop</li>
</ul>
<img src="http://nvie.com/img/main-branches@2x.png">

<p>其中master分支为稳定分支，用来发布稳定的软件版本。<br>develop分支为开发分支，用于开发人员开发  </p>
<h2 id="扩展分支"><a href="#扩展分支" class="headerlink" title="扩展分支"></a>扩展分支</h2><p>除了master和develop分支，我们还可以使用其他扩展分支，来支持更加丰富的需求。如下：</p>
<ul>
<li>团队成员需要并行开发新功能</li>
<li>追踪某个功能的开发流程</li>
<li>准备发布线上 release版本</li>
<li>快速修复线上 bug</li>
</ul>
<p>跟主要分支不同的是，扩展分支只有有限的存活时间，当功能完成后，这些分支都将被删除。</p>
<p>为了满足以上需求，我们会用到的扩展分支有：</p>
<ul>
<li>feature 分支 （用于团队成员并行开发新功能）</li>
<li>release 分支 (用于发布release版本，并标记tag)</li>
<li>hotfix 分支 (用于快速修复线上bug)</li>
</ul>
<p>下面将会详细介绍这些扩展分支的使用过程。</p>
<h2 id="feature-分支"><a href="#feature-分支" class="headerlink" title="feature 分支"></a>feature 分支</h2><p>可能来自于:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">develop</span><br></pre></td></tr></table></figure>

<p>必须要合并回：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">develop</span><br></pre></td></tr></table></figure>

<p>分支命名：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">除了master develop release-* hotfix-* 之外的其他名字</span><br><span class="line">（建议使用feature-*）</span><br></pre></td></tr></table></figure>

<img src="http://nvie.com/img/fb@2x.png">

<p>feature分支用来为后续release版本开发新的特性或者功能。开始开发新feature时，并不清楚该特性会在何时被合并回去。只要该特性还在开发中，该feature分支就会一直存在。 feature分支最终会被合并进develop分支（如果确定在下一个release版本中增加该功能），或者被舍弃掉（比如失败的新功能实验）</p>
<p>feature分支仅仅存在开发者的本地repo中，不应该被提交到origin</p>
<h3 id="新建一个feature分支"><a href="#新建一个feature分支" class="headerlink" title="新建一个feature分支"></a>新建一个feature分支</h3><p>当开始开发一个新特性时，从develop分支上切一个feature分支</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git checkout -b myfeature develop</span><br><span class="line">Switched to a new branch &quot;myfeature&quot;</span><br></pre></td></tr></table></figure>

<h3 id="新特性开发完，合并回develop分支"><a href="#新特性开发完，合并回develop分支" class="headerlink" title="新特性开发完，合并回develop分支"></a>新特性开发完，合并回develop分支</h3><p>当明确后续版本将要加入这些新特性时， 将feature分支合并到develop分支。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git checkout develop</span><br><span class="line">Switched to branch &#x27;develop&#x27;</span><br><span class="line">$ git merge --no-ff myfeature</span><br><span class="line">Updating ea1b82a..05e9557</span><br><span class="line">(Summary of changes)</span><br><span class="line">$ git branch -d myfeature</span><br><span class="line">Deleted branch myfeature (was 05e9557).</span><br><span class="line">$ git push origin develop</span><br></pre></td></tr></table></figure>

<p>–no-ff参数表示合并必须要产生一个新的commit操作，而不是使用git默认的“fast-forward”模式。这样做可以避免丢失feature分支存在的历史信息并且可以将feature分支的多次commit合并为develop分支的一次提交。</p>
<p>二者的区别见下图：<br><img src="http://nvie.com/img/merge-without-ff@2x.png"></p>
<p>从图中可以看出，在不使用“–no-ff”的情况下，跟踪一个已实现的特性的开发历史将变得十分麻烦（你仅仅只能从git log的信息中推断分支的开发情况）， 而且特性的回滚也将让人头痛。</p>
<p>虽然使用“–no-ff”会增加一些commit，并且合并的速度要稍慢一些，但从长远看绝对是利大于弊的。</p>
<h2 id="release-分支"><a href="#release-分支" class="headerlink" title="release 分支"></a>release 分支</h2><p>可能来自于:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">develop</span><br></pre></td></tr></table></figure>

<p>必须要合并回：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">develop and master</span><br></pre></td></tr></table></figure>

<p>分支命名：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">release-*</span><br></pre></td></tr></table></figure>

<p>release分支是为新的线上版本的发布做准备的。release分支允许在上线前做最后的修改。此外它还允许很小的bug fix和更新一些元数据（如version number、 build date 等）。这些事情交给了release分支处理，develop分支则可以专注地为下一次版本发布继续开发新特性了。</p>
<p>从develop分支上切出release分支的正确时刻，应该是在develop分支对于新版本的功能已经到达一个比较理想的状态，新版本的新增特性的分支都已经验证通过并合并回develop分支上。</p>
<p>新版本的版本号，是在release分支从develop分支切出时确认的，而不是在develop分支上确认后再切出release分支。</p>
<h3 id="新建release分支"><a href="#新建release分支" class="headerlink" title="新建release分支"></a>新建release分支</h3><p>release分支是从develop分支产生的。比如，当前线上的版本是1.1.5并且我们有一个新版本即将发布。develop分支的功能已经就绪并且我们决定新版本的版本号为1.2（不是1.1.6或者2）。因此我们从develop分支上切出release分支，release分支命名上反映版本号</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git checkout -b release-1.2 develop</span><br><span class="line">Switched to a new branch &quot;release-1.2&quot;</span><br><span class="line">$ ./bump-version.sh 1.2</span><br><span class="line">Files modified successfully, version bumped to 1.2.</span><br><span class="line">$ git commit -a -m &quot;Bumped version number to 1.2&quot;</span><br><span class="line">[release-1.2 74d9424] Bumped version number to 1.2</span><br><span class="line">1 files changed, 1 insertions(+), 1 deletions(-)</span><br></pre></td></tr></table></figure>

<p>切到release分支上后，我们使用bump-version.sh来修改所有涉及版本号的内容（假设我们有这个脚本），并将该分支交由qa进行测试。</p>
<p>release分支会存在一段时间，直到qa测试完所有问题并修复掉所有bug，达到上线状态。release分支不再接受大的feature修改，大的feture应该先被合并到develop分支，并在下次发布新版本时，包含进新的release分支中。</p>
<h3 id="完成release分支"><a href="#完成release分支" class="headerlink" title="完成release分支"></a>完成release分支</h3><p>当release分支达到准上线状态时，就可以进行后续操作了。首先应该讲release分支合并进master分支；其次master分支合并后，应该给master分支打上浅简易懂的tag；最终release分支应该merge回develop分支，因此在release上的新feature的bug fix也会被包含进develop中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git checkout master</span><br><span class="line">Switched to branch &#x27;master&#x27;</span><br><span class="line">$ git merge --no-ff release-1.2</span><br><span class="line">Merge made by recursive.</span><br><span class="line">(Summary of changes)</span><br><span class="line">$ git tag -a 1.2</span><br></pre></td></tr></table></figure>

<p>此时发布已经完成，并且已打上了tag作为后续的参考</p>
<p>将release内容，merge回develop分支</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git checkout develop</span><br><span class="line">Switched to branch &#x27;develop&#x27;</span><br><span class="line">$ git merge --no-ff release-1.2</span><br><span class="line">Merge made by recursive.</span><br><span class="line">(Summary of changes)</span><br></pre></td></tr></table></figure>

<p>这一步可能会产生conflict， 修复再提交就可以啦。</p>
<p>最后，删除release分支</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git branch -d release-1.2</span><br><span class="line">Deleted branch release-1.2 (was ff452fe).</span><br></pre></td></tr></table></figure>


<h2 id="hotfix-分支"><a href="#hotfix-分支" class="headerlink" title="hotfix 分支"></a>hotfix 分支</h2><p>可能来自于:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">master</span><br></pre></td></tr></table></figure>

<p>最终要合并回：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">develop and master</span><br></pre></td></tr></table></figure>

<p>分支命名：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hotfix-*</span><br></pre></td></tr></table></figure>

<p>hotfix分支和release分支很相似，他们都是用来发布新版本的，尽管hotfix属于非正常发布的。当线上版本出现重大bug并且必须要马上解决时，hotfix分支这时候就派上用场了。严重的线上bug必须要立即解决，从master分支上切出hotfix分支来处理这些bug，并标记上相应的tag.</p>
<img src="http://nvie.com/img/hotfix-branches@2x.png">

<p>hotfix分支保证了团队成员可以继续在develop分支上进行开发，而线上的bug有能得到及时的修复。</p>
<h3 id="新建hotfix分支"><a href="#新建hotfix分支" class="headerlink" title="新建hotfix分支"></a>新建hotfix分支</h3><p>hotfix分支是从master分支切出的。比如，假设当前线上版本是v1.2，v1.2版本有重大的问题。但develop分支目前正在开发中，还不稳定，因此我们需要从master分支切出hotfix分支来解决问题。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git checkout -b hotfix-1.2.1 master</span><br><span class="line">Switched to a new branch &quot;hotfix-1.2.1&quot;</span><br><span class="line">$ ./bump-version.sh 1.2.1</span><br><span class="line">Files modified successfully, version bumped to 1.2.1.</span><br><span class="line">$ git commit -a -m &quot;Bumped version number to 1.2.1&quot;</span><br><span class="line">[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1</span><br><span class="line">1 files changed, 1 insertions(+), 1 deletions(-)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>(不要忘记修改新的版本号)</p>
<p>修复完bug, 并commit</p>
<h3 id="完成hotfix分支"><a href="#完成hotfix分支" class="headerlink" title="完成hotfix分支"></a>完成hotfix分支</h3><p>完成hotfix分支后，需要合并回master分支。并且还要合并回develop分支，这样就能保证发布下个版本时，本次版本的bug fix肯定会包含其中。</p>
<p>首先更新master，并打上标记</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git checkout master</span><br><span class="line">Switched to branch &#x27;master&#x27;</span><br><span class="line">$ git merge --no-ff hotfix-1.2.1</span><br><span class="line">Merge made by recursive.</span><br><span class="line">(Summary of changes)</span><br><span class="line">$ git tag -a 1.2.1</span><br></pre></td></tr></table></figure>

<p>然后将hotfix合并回develop</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git checkout develop</span><br><span class="line">Switched to branch &#x27;develop&#x27;</span><br><span class="line">$ git merge --no-ff hotfix-1.2.1</span><br><span class="line">Merge made by recursive.</span><br><span class="line">(Summary of changes)</span><br></pre></td></tr></table></figure>

<p>上面的规则有一个例外。当当前有release分支存在时， 应该将hotfix分支合并回release分支， 这样操作，最终也会导致hotfix做的修改最终合并回develop分支（当release分支完成使命，合并回develop分支时）。如果develop分支也迫切需要这些bug fix并且不能等待release分支合并时，也可以直接将hotfix合并到develop分支上。</p>
<p>最后，删除这个临时分支</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git branch -d hotfix-1.2.1</span><br><span class="line">Deleted branch hotfix-1.2.1 (was abbe5d6).</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>文章头部的大图对我们的工程开发是极其有用的，它的组织形式是很优雅和浅简易懂的，能够更好的帮助团队成员理解分支开发和发布流程。</p>
<p>获取高清的pdf,点击<a href="http://nvie.com/files/Git-branching-model.pdf">这里</a></p>
<hr>
<p>【原文链接】：<a href="http://nvie.com/posts/a-successful-git-branching-model/">A successful Git branching model</a></p>
]]></content>
      <categories>
        <category>工程化</category>
      </categories>
      <tags>
        <tag>git branch</tag>
      </tags>
  </entry>
  <entry>
    <title>一种使用redis实现频率限制的错误方式及解释</title>
    <url>/posts/4b81ce8f/</url>
    <content><![CDATA[<h1 id="一种使用redis实现频率限制的错误方式及解释"><a href="#一种使用redis实现频率限制的错误方式及解释" class="headerlink" title="一种使用redis实现频率限制的错误方式及解释"></a>一种使用redis实现频率限制的错误方式及解释</h1><p>redis作为如今最流行的缓存软件广泛应用于互联网业务的方方面面，而频率限制又是很常见的业务场景，如常见的投票、抢购、秒杀等场景。redis由于全部基于内存操作，在读写性能上表现相当给力，因此很多业务中都使用redis来实现频率限制。</p>
<p>网上的教程已经汗牛充栋，我这里仅简单地介绍下原理，然后重点介绍下在高并发场景下，简单地使用redis将不能保证操作的原子性，频率限制会形同虚设。</p>
<span id="more"></span>

<h2 id="一、一种redis实现频率限制的常见方式"><a href="#一、一种redis实现频率限制的常见方式" class="headerlink" title="一、一种redis实现频率限制的常见方式"></a>一、一种redis实现频率限制的常见方式</h2><p>参考redis官网</a><a href="https://redis.io/commands/INCR#pattern-rate-limiter-1">参考redis官网</a></p>
<p>常见的有如下的方式来实现，以php为例。</p>
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line">    <span class="comment">// limit = 10 expire = 1， 代表限制1秒内最多10次访问</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">rateLimit</span>(<span class="params"><span class="variable">$key</span>, <span class="variable">$limit</span> = <span class="number">10</span>, <span class="variable">$expire</span> = <span class="number">1</span></span>)</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="comment">// 获取redis实例</span></span><br><span class="line">        <span class="variable">$redis</span> = \Redis();</span><br><span class="line">        <span class="variable">$redis</span>-&gt;connnect(<span class="string">&#x27;127.0.0.1&#x27;</span>, <span class="number">6379</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取当前的计数器的值。命名为op1(操作1)</span></span><br><span class="line">        <span class="variable">$current</span> = redis-&gt;get(<span class="variable">$key</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 如果当前计数器的值存在且计数器已经超过限制，返回失败</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="variable">$current</span> != <span class="literal">null</span> &amp;&amp; <span class="variable">$current</span> &gt;= <span class="variable">$limit</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 获取计数器的存活时间</span></span><br><span class="line">            <span class="variable">$ttl</span> = <span class="variable">$redis</span>-&gt;ttl(<span class="variable">$key</span>);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 开始一个事务 // 命名为op2（操作2）</span></span><br><span class="line">            <span class="variable">$redis</span>-&gt;multi(\Redis::MULTI);</span><br><span class="line">            <span class="comment">// 将计数器原子加1，若计数器不存在，则创建计数器</span></span><br><span class="line">            <span class="variable">$redis</span>-&gt;incr(<span class="variable">$key</span>);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 若存活时间小于0，代表计数器之前不存在，是刚刚创建的，则设置一个存活时间</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="variable">$ttl</span> &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="variable">$redis</span>-&gt;expire(<span class="variable">$key</span>, <span class="variable">$expire</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 提交事务</span></span><br><span class="line">            <span class="variable">$redis</span>-&gt;exec();</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>大家看代码加上注释，相信已经能明白实现的原理。这种实现方法，在大多数场景下也运行的非常好，但在高并发场景下就会有很严重的问题。</p>
<h2 id="二、高并发时存在的坑"><a href="#二、高并发时存在的坑" class="headerlink" title="二、高并发时存在的坑"></a>二、高并发时存在的坑</h2><p>单从代码逻辑上来看，是没有丝毫问题的。但必须要注意的是，php（或其他语言）调用redis服务时都是典型的client-server模型，首先要进行3次握手，才能建立连接，之后每一次通信，都是发送一个tcp报文，再封装成ip报文，ip报文在经过n个路由器或交换机，最终才抵达redis服务器（假设php程序和redis不在同一机器上）。其中的网络开销是要远远超过任何一个复杂php操作的执行时间的。</p>
<p>而redis奉行的是极简主义，其单进程单线程模型，保证了每个redis命令单独执行的原子性（如果是事务的话，会将事务里多个命令打包执行，也具有原子性）。但redis无法保证多个命令执行的原子性。 </p>
<p>而从上面代码可知，实现频率限制，通过两步操作来实现的（忽略获取存活时间的一步）。</p>
<ol>
<li><p>op1： 读取当前计数器的值</p>
</li>
<li><p>op2: 若超出频率限制，则返回失败，否则通过事务实现原子性加1</p>
</li>
</ol>
<p>从上面的分析可知，redis是无法保证op1和op2原子性执行的，最终的结果会跟我们设想的大相径庭。</p>
<h3 id="2-1-举例分析"><a href="#2-1-举例分析" class="headerlink" title="2.1 举例分析"></a>2.1 举例分析</h3><h4 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h4><p>我想实现一个1秒钟内限制最多访问10次。</p>
<h5 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h5><p>(1) 我们将1秒分成1000份，每一份为1ms， 分别用[t1, t2, t3, t4, … t1000]来表示</p>
<p>(2) 在t1时刻，来了1000个并发请求，分别用[req1, req2, req3, … req1000]来表示</p>
<p>(3) 假如php-fpm和redis不在同一机房，请求一次redis花费的时间是100ms</p>
<p>(4) 读取计数器的值和递增计数器的值的操作，分别为[op1, op2]</p>
<p>(5) redis是单个队列顺序执行命令，我使用数组来表示</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">queue = [</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;req&#x27; : req1,  // req代表是哪个请求</span><br><span class="line">        &#x27;op&#x27;  : op1    // op 代表该请求执行的哪个操作</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;req&#x27; : xxx,</span><br><span class="line">        &#x27;op&#x27;  : xxx,</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>


<h4 id="t1时刻"><a href="#t1时刻" class="headerlink" title="t1时刻"></a>t1时刻</h4><p>在t1时刻有1000个并发请求过来，最终会有1000个op1操作，会加入到redis执行的队列中，其结果为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">queue = [</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;req&#x27;: req1,</span><br><span class="line">        &#x27;op&#x27; : op1,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;req&#x27;: req2,</span><br><span class="line">        &#x27;op&#x27; : op1,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;req&#x27;: req3,</span><br><span class="line">        &#x27;op&#x27; : op1,</span><br><span class="line">    &#125;,</span><br><span class="line">    ...</span><br><span class="line">    &#123;</span><br><span class="line">        &#x27;req&#x27;: req1000,</span><br><span class="line">        &#x27;op&#x27; : op1,</span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>redis执行完这些命令，并且会在t100时刻将结果返回。</p>
<h4 id="t100时刻"><a href="#t100时刻" class="headerlink" title="t100时刻"></a>t100时刻</h4><p> 此时所有的请求都会拿到结果，每个请求都会知道此时计数器的值为1，它们都会来执行op2，并且返回true。</p>
<h4 id="t100-t1000时间段"><a href="#t100-t1000时间段" class="headerlink" title="t100-t1000时间段"></a>t100-t1000时间段</h4><p> 每个请求都会执行op2，并且将op2的命令发给redis处理，此时redis执行的队列如下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    queue = [</span><br><span class="line">        &#123;</span><br><span class="line">            &#x27;req&#x27;: req1,</span><br><span class="line">            &#x27;op&#x27; : op2,</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &#x27;req&#x27;: req2,</span><br><span class="line">            &#x27;op&#x27; : op2,</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &#x27;req&#x27;: req3,</span><br><span class="line">            &#x27;op&#x27; : op2,</span><br><span class="line">        &#125;,</span><br><span class="line">        ...</span><br><span class="line">        &#123;</span><br><span class="line">            &#x27;req&#x27;: req1000,</span><br><span class="line">            &#x27;op&#x27; : op2,</span><br><span class="line">        &#125;,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 注：由于网络环境的变化，req到达redis的顺序并不一定是req1,req2....req1000, 此处为举例，忽略细节</span><br></pre></td></tr></table></figure>

<h4 id="t1000时刻"><a href="#t1000时刻" class="headerlink" title="t1000时刻"></a>t1000时刻</h4><p>此时正好过了一秒，可以看下我们最终的结果。</p>
<p>(1) 1000请求都通过了频率限制，将有权限执行后续操作</p>
<p>(2) 计数器累加到了1000</p>
<p>哈哈，我们为了提供系统安全而设计的频率限制，在高并发场景下形同虚设，惊不惊喜！</p>
<h3 id="2-2-原因"><a href="#2-2-原因" class="headerlink" title="2.2 原因"></a>2.2 原因</h3><p>(1) 高并发场景下，频率限制的两步操作在redis执行时是非原子性的</p>
<p>(2) 请求redis带来的时间开销是要远远大于普通代码执行的。</p>
<h2 id="三、实验"><a href="#三、实验" class="headerlink" title="三、实验"></a>三、实验</h2><p>可以使用swoole多进程来模拟并发请求，执行上面的代码，下面是我使用100个并发程序，运行得到的结果。（为了使效果更直观，php和redis位于不同的机房，请求的时间开销为130ms左右）</p>
<h3 id="3-1-目标"><a href="#3-1-目标" class="headerlink" title="3.1 目标"></a>3.1 目标</h3><p>频率限制10分钟内最多操作10次</p>
<h3 id="基本环境"><a href="#基本环境" class="headerlink" title="基本环境"></a>基本环境</h3><p>(1) swoole模拟100个并发访问<br>(2) php和redis跨机房部署、延迟130ms</p>
<h3 id="3-2-代码"><a href="#3-2-代码" class="headerlink" title="3.2 代码"></a>3.2 代码</h3><figure class="highlight php"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line">    <span class="variable">$workNum</span> = <span class="number">100</span>;</span><br><span class="line"></span><br><span class="line">    <span class="variable">$stdout</span> = <span class="string">&#x27;&#x27;</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="variable">$i</span> = <span class="number">0</span>; <span class="variable">$i</span> &lt; <span class="variable">$workNum</span>; <span class="variable">$i</span>++) &#123;</span><br><span class="line">        <span class="variable">$process</span>       = <span class="keyword">new</span> swoole_process(<span class="string">&#x27;rateLimit&#x27;</span>, <span class="variable">$stdout</span>);</span><br><span class="line">        <span class="variable">$pid</span>           = <span class="variable">$process</span>-&gt;start();</span><br><span class="line">        <span class="variable">$workers</span>[<span class="variable">$pid</span>] = <span class="variable">$process</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">rateLimit</span>(<span class="params">swoole_process <span class="variable">$worker</span></span>)</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="variable">$redis</span> = <span class="keyword">new</span> \Redis();</span><br><span class="line">        <span class="variable">$redis</span>-&gt;connect(<span class="string">&#x27;xxx.xxx.xxx.xxx&#x27;</span>, xxx);</span><br><span class="line">        <span class="variable">$redis</span>-&gt;auth(<span class="string">&#x27;i dont know&#x27;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="variable">$limit</span>  = <span class="number">10</span>;</span><br><span class="line">        <span class="variable">$expire</span> = <span class="number">600</span>;</span><br><span class="line">        <span class="variable">$key</span>    = <span class="string">&#x27;testbyclf&#x27;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="variable">$current</span> = <span class="variable">$redis</span>-&gt;get(<span class="variable">$key</span>);</span><br><span class="line">        <span class="keyword">if</span> (<span class="variable">$current</span> != <span class="literal">null</span> &amp;&amp; <span class="variable">$current</span> &gt;= <span class="variable">$limit</span>) &#123;</span><br><span class="line">                <span class="keyword">echo</span> <span class="string">&quot;permission rejected\n&quot;</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="variable">$ttl</span> = <span class="variable">$redis</span>-&gt;ttl(<span class="variable">$key</span>);</span><br><span class="line"></span><br><span class="line">                <span class="variable">$redis</span>-&gt;multi(\Redis::MULTI);</span><br><span class="line">                <span class="variable">$redis</span>-&gt;incr(<span class="variable">$key</span>);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (<span class="variable">$ttl</span> &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                        <span class="variable">$redis</span>-&gt;expire(<span class="variable">$key</span>, <span class="variable">$expire</span>);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="variable">$redis</span>-&gt;exec();</span><br><span class="line">                <span class="keyword">echo</span> <span class="string">&quot;permission passed\n&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="variable">$worker</span>-&gt;exit();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-3-结果"><a href="#3-3-结果" class="headerlink" title="3.3 结果"></a>3.3 结果</h3><h4 id="swoole输出"><a href="#swoole输出" class="headerlink" title="swoole输出"></a>swoole输出</h4><p><img src="/images/swoole.png" alt="swoole.png"></p>
<h4 id="redis输出"><a href="#redis输出" class="headerlink" title="redis输出"></a>redis输出</h4><p><img src="/images/redis.png" alt="redis.png"></p>
<h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><p>(1) 并发请求访问共享资源时，要保证原子操作</p>
<p>(2) 要区分对待访问服务和普通代码执行之间，时间开销的巨大差距</p>
<h2 id="五、后续"><a href="#五、后续" class="headerlink" title="五、后续"></a>五、后续</h2><h4 id="既然在高并发场景时，使用简单的redis命令来实现有诸多的弊病，那是否有其他方案来解决呢？"><a href="#既然在高并发场景时，使用简单的redis命令来实现有诸多的弊病，那是否有其他方案来解决呢？" class="headerlink" title="既然在高并发场景时，使用简单的redis命令来实现有诸多的弊病，那是否有其他方案来解决呢？"></a>既然在高并发场景时，使用简单的redis命令来实现有诸多的弊病，那是否有其他方案来解决呢？</h4><p>其实，只需要保证op1和op2操作的原子性，就能解决高并发时的问题。目前的方案有两种：</p>
<p>(1) 使用lua脚本在redis中实现频率限制的功能。redis是能够保证lua脚本执行的原子性的，并且还将多次网络开销变成一次网络开销，速度上会大大提高</p>
<p>(2) redis 4.0以上版本支持了模块功能，目前官方已经有成熟的频率限制的第三方模块，可以通过<a href="https://redis.io/modules">redis官网-module</a>了解详情。</p>
]]></content>
      <tags>
        <tag>redis 频率限制 高并发</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql事务隔离级设置</title>
    <url>/posts/43eca55f/</url>
    <content><![CDATA[<h2 id="mysql-事务隔离级设置"><a href="#mysql-事务隔离级设置" class="headerlink" title="mysql 事务隔离级设置"></a>mysql 事务隔离级设置</h2><h3 id="如何查看当前SESSION的事务隔离级"><a href="#如何查看当前SESSION的事务隔离级" class="headerlink" title="如何查看当前SESSION的事务隔离级"></a>如何查看当前SESSION的事务隔离级</h3><p>mysql 默认的事务隔离级是 REPEATABLE-READ</p>
<p>可以通过以下命令查看当前session的事务隔离级（5.7.20之前）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MariaDB [(none)]&gt; select @@session.tx_isolation;</span><br><span class="line">+------------------------+</span><br><span class="line">| @@session.tx_isolation |</span><br><span class="line">+------------------------+</span><br><span class="line">| REPEATABLE-READ        |</span><br><span class="line">+------------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h3 id="如何修改事务隔离级"><a href="#如何修改事务隔离级" class="headerlink" title="如何修改事务隔离级"></a>如何修改事务隔离级</h3><h4 id="参考-mysql手册"><a href="#参考-mysql手册" class="headerlink" title="参考 mysql手册"></a>参考 <a href="https://dev.mysql.com/doc/refman/5.7/en/set-transaction.html">mysql手册</a></h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SET [GLOBAL | SESSION] TRANSACTION</span><br><span class="line">    transaction_characteristic [, transaction_characteristic] ...</span><br><span class="line"></span><br><span class="line">transaction_characteristic:</span><br><span class="line">    ISOLATION LEVEL level</span><br><span class="line">  | READ WRITE</span><br><span class="line">  | READ ONLY</span><br><span class="line"></span><br><span class="line">level:</span><br><span class="line">     REPEATABLE READ</span><br><span class="line">   | READ COMMITTED</span><br><span class="line">   | READ UNCOMMITTED</span><br><span class="line">   | SERIALIZABLE</span><br></pre></td></tr></table></figure>

<ol>
<li>GLOBAL:代表对随后所有的SESSION都生效，已经建立的SESSION不受影响</li>
<li>SESSION: 代表只对当前的SESSION生效</li>
</ol>
]]></content>
      <tags>
        <tag>mysql 事务命令</tag>
      </tags>
  </entry>
  <entry>
    <title>Tcp协议TIME_WAIT状态</title>
    <url>/posts/d4a8876c/</url>
    <content><![CDATA[<h2 id="TIME-WAIT状态"><a href="#TIME-WAIT状态" class="headerlink" title="TIME_WAIT状态"></a>TIME_WAIT状态</h2><h3 id="TIME-WAIT状态何时发生？-状态持续时间为多久？"><a href="#TIME-WAIT状态何时发生？-状态持续时间为多久？" class="headerlink" title="TIME_WAIT状态何时发生？ 状态持续时间为多久？"></a>TIME_WAIT状态何时发生？ 状态持续时间为多久？</h3><p>TIME_WAIT状态在TCP4次挥手是产生。当客户端收到服务端返回FIN信号时，进入TIME_WAIT状态并且向服务端返回ACK，告知服务端我已经收到你的FIN信息。</p>
<p>TIME_WAIT状态的时间是最长分节时间（maximun segment lifetime, MSL）的两倍， 有时候称之为2MSL。 最长分节时间是指，一次TCP报文在服务端和客户端之前传送存活的最长时间，若超过这个时间，该报文仍未到达目的地，则可认为该报文已被丢弃。</p>
<p>最长分节时间一般由ip报文的TTL标识，TTL代表一个ip报文传递时通过一个ip报文的最大跳数（255），ip报文每经过一个路由器，TTL会减1，当TTL为0时，路由器会将该报文丢弃。</p>
<h3 id="为何需要该状态？-该状态设置的时间为何是2MSL"><a href="#为何需要该状态？-该状态设置的时间为何是2MSL" class="headerlink" title="为何需要该状态？  该状态设置的时间为何是2MSL?"></a>为何需要该状态？  该状态设置的时间为何是2MSL?</h3><span id="more"></span>

<p>该状态存在有两个理由。<br>（1） 可靠地实现TCP全双工连接的终止<br>这句话比较拗口。 意思是在在四次挥手时，如果最后的分节报文丢失（ip报文会丢），客户端也能够正常处理结果，而不会出错。</p>
<p>有这样一种情况。四次挥手时，客户端最后发送给服务端的ACK丢失时， 服务端会认为客户端没收到自己的FIN，然后会重传FIN。此时客户端其实已经收到过第一个FIN了，如果客户端不维护状态信息，它将返回一个RST分节，该分节将会被服务端解析成错误。</p>
<p>因此如果tcp想可靠地关闭连接，那就要能够处理四次挥手时任何一个分节数据丢失的情况。</p>
<p>（2） 保证老的重复分节已经在网络中消失。<br>假设a和b之间建立了一个连接A1-B1， 连接关闭后，a和b之间又建立了连接A2-B2。 但连接A1-B1关闭后，可能有些报文数据由于网络原因（如发生了路由循环）延迟了一段时间后，又到底了a或者b。但此时已经是A2-B2连接，该报文是无效的。</p>
<p> 设置TIME_WAIT时间为2MSL，就保证了建立新的连接时，之前的连接报文在网络中都已经失效了。</p>
]]></content>
      <tags>
        <tag>tcp/ip</tag>
      </tags>
  </entry>
  <entry>
    <title>redis内存使用统计及碎片率分析</title>
    <url>/posts/a39640ef/</url>
    <content><![CDATA[<h1 id="如何获取redis内存使用情况"><a href="#如何获取redis内存使用情况" class="headerlink" title="如何获取redis内存使用情况"></a>如何获取redis内存使用情况</h1><p>redis提供了info命令，可以获取redis内存使用情况。<br>其中关于redis内存的部分有七个参数，used_memory、used_memory_human、used_memory_rss、used_memory_peak、used_memory_peak_human、mem_fragmentation_ratio、used_memory_lua和mem_allocator。</p>
<p>各参数的含义如下：</p>
<ul>
<li>used_memory : 由 Redis 分配器分配的内存总量，以字节（byte）为单位</li>
<li>used_memory_human : 以人类可读的格式返回 Redis 分配的内存总量</li>
<li>used_memory_rss : 从操作系统的角度，返回Redis已分配的内存总量（俗称常驻集大小）。这个值和 top 、 ps 等命令的输出一致。</li>
<li>used_memory_peak : Redis的内存消耗峰值（以字节为单位）</li>
<li>used_memory_peak_human : 以人类可读的格式返回 Redis 的内存消耗峰值</li>
<li>mem_fragmentation_ratio : used_memory_rss 和 used_memory 之间的比率</li>
<li>used_memory_lua : Lua 引擎所使用的内存大小（以字节为单位）</li>
<li>mem_allocator : 在编译时指定的，Redis所使用的内存分配器。可以是 libc 、 jemalloc 或者 tcmalloc 。</li>
</ul>
<span id="more"></span>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">redis 127.0.0.1:6389&gt; info</span><br><span class="line">    ...</span><br><span class="line">    used_memory:832323728</span><br><span class="line">    used_memory_human:793.77M</span><br><span class="line">    used_memory_rss:874582016</span><br><span class="line">    used_memory_peak:1067840504</span><br><span class="line">    used_memory_peak_human:1018.37M</span><br><span class="line">    mem_fragmentation_ratio:1.05</span><br><span class="line">    mem_allocator:jemalloc-2.2.5</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p>  从以上参数的官方介绍来看，统计redis内存使用量主要是used_memory used_memory_rss used_memory_lua,这三部分。其他参数（除mem_allocator）都是由它们产生的统计值。</p>
<p>其中</p>
<ul>
<li><p>used_memory_peak统计的是used_memory的最大值。</p>
</li>
<li><p>mem_fragmentation_ratio统计的是used_memory_rss和used_memory的比值，其值与1的大小关系，代表redis的内存碎片率情况。正常情况下，从操作系统统计的内存使用量（used_memory_rss）应该稍大于redis内存分配器统计的内存使用（used_momory）,即mem_fragmentation_ratio应稍大于1。若mem_fragmentation远大于1，代表操作系统实际分配内存要远大于redis自身统计值，代表redis内部可能有内存碎片，没有被redis统计到；若mem_fragmentation小于1，代表操作系统实际分配内存小于redis自身统计值，此时表示Redis的部分内存被操作系统换出交换空间了，此时redis会产生明显的延迟。</p>
</li>
</ul>
<h1 id="从源码跟踪这些参数"><a href="#从源码跟踪这些参数" class="headerlink" title="从源码跟踪这些参数"></a>从源码跟踪这些参数</h1><p>获取INFO返回信息的入口定义在redis.c的genRedisInfoString中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//redis.c</span><br><span class="line"></span><br><span class="line">    sds genRedisInfoString(char *section) &#123;</span><br><span class="line">    ...</span><br><span class="line">    /* Memory */</span><br><span class="line">        info = sdscatprintf(info,</span><br><span class="line">            &quot;# Memory\r\n&quot;</span><br><span class="line">            &quot;used_memory:%zu\r\n&quot;</span><br><span class="line">            &quot;used_memory_human:%s\r\n&quot;</span><br><span class="line">            &quot;used_memory_rss:%zu\r\n&quot;</span><br><span class="line">            &quot;used_memory_peak:%zu\r\n&quot;</span><br><span class="line">            &quot;used_memory_peak_human:%s\r\n&quot;</span><br><span class="line">            &quot;used_memory_lua:%lld\r\n&quot;</span><br><span class="line">            &quot;mem_fragmentation_ratio:%.2f\r\n&quot;</span><br><span class="line">            &quot;mem_allocator:%s\r\n&quot;,</span><br><span class="line">            zmalloc_used,</span><br><span class="line">            hmem,</span><br><span class="line">            server.resident_set_size,</span><br><span class="line">            server.stat_peak_memory,</span><br><span class="line">            peak_hmem,</span><br><span class="line">            ((long long)lua_gc(server.lua,LUA_GCCOUNT,0))*1024LL,</span><br><span class="line">            zmalloc_get_fragmentation_ratio(server.resident_set_size),</span><br><span class="line">            ZMALLOC_LIB</span><br><span class="line">            );</span><br><span class="line">    ...</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>


<pre><code>used_memory       =&gt; zmalloc_used
used_memory_rss   =&gt; server.resident_set_size
used_memory_peak  =&gt; server.stat_pear_memory
used_memory_lua   =&gt; lua_gc(server.lua,LUA_GCCOUNT,0))*1024LL</code></pre><h2 id="跟踪used-memory"><a href="#跟踪used-memory" class="headerlink" title="跟踪used_memory"></a>跟踪used_memory</h2><p>used_memory对应的变量zmalloc_used，是通过zmalloc_used_memory()返回的，该函数定义在zmalloc.c中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// zmalloc.c</span><br><span class="line"></span><br><span class="line">size_t zmalloc_used_memory(void) &#123;</span><br><span class="line">    size_t um;</span><br><span class="line"></span><br><span class="line">    if (zmalloc_thread_safe) &#123;</span><br><span class="line">#ifdef HAVE_ATOMIC</span><br><span class="line">        um = __sync_add_and_fetch(&amp;used_memory, 0);</span><br><span class="line">#else</span><br><span class="line">        pthread_mutex_lock(&amp;used_memory_mutex);</span><br><span class="line">        um = used_memory;</span><br><span class="line">        pthread_mutex_unlock(&amp;used_memory_mutex);</span><br><span class="line">#endif</span><br><span class="line">    &#125;</span><br><span class="line">    else &#123;</span><br><span class="line">        um = used_memory;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return um;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>从该函数可以看出，zmalloc_used的值取自used_memory变量。当然针对是否线程安全以及是否是有原子性操作，对used_memory的读取策略不同，但都是读取的used_memory的值。</p>
<p>used_memory的初始化以及修改操作都在zmalloc.c中完成。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//zmalloc.c</span><br><span class="line"></span><br><span class="line">// 根据HAVE_ATOMIC来定义used_memory的加和减的方式</span><br><span class="line">#ifdef HAVE_ATOMIC</span><br><span class="line">#define update_zmalloc_stat_add(__n) __sync_add_and_fetch(&amp;used_memory, (__n))</span><br><span class="line">#define update_zmalloc_stat_sub(__n) __sync_sub_and_fetch(&amp;used_memory, (__n))</span><br><span class="line">#else</span><br><span class="line">#define update_zmalloc_stat_add(__n) do &#123; \</span><br><span class="line">    pthread_mutex_lock(&amp;used_memory_mutex); \</span><br><span class="line">    used_memory += (__n); \</span><br><span class="line">    pthread_mutex_unlock(&amp;used_memory_mutex); \</span><br><span class="line">&#125; while(0)</span><br><span class="line"></span><br><span class="line">#define update_zmalloc_stat_sub(__n) do &#123; \</span><br><span class="line">    pthread_mutex_lock(&amp;used_memory_mutex); \</span><br><span class="line">    used_memory -= (__n); \</span><br><span class="line">    pthread_mutex_unlock(&amp;used_memory_mutex); \</span><br><span class="line">&#125; while(0)</span><br><span class="line"></span><br><span class="line">#endif</span><br><span class="line"></span><br><span class="line">#define update_zmalloc_stat_alloc(__n) do &#123; \</span><br><span class="line">    size_t _n = (__n); \</span><br><span class="line">    if (_n&amp;(sizeof(long)-1)) _n += sizeof(long)-(_n&amp;(sizeof(long)-1)); \</span><br><span class="line">    if (zmalloc_thread_safe) &#123; \</span><br><span class="line">        update_zmalloc_stat_add(_n); \</span><br><span class="line">    &#125; else &#123; \</span><br><span class="line">        used_memory += _n; \</span><br><span class="line">    &#125; \</span><br><span class="line">&#125; while(0)</span><br><span class="line"></span><br><span class="line">#define update_zmalloc_stat_free(__n) do &#123; \</span><br><span class="line">    size_t _n = (__n); \</span><br><span class="line">    if (_n&amp;(sizeof(long)-1)) _n += sizeof(long)-(_n&amp;(sizeof(long)-1)); \</span><br><span class="line">    if (zmalloc_thread_safe) &#123; \</span><br><span class="line">        update_zmalloc_stat_sub(_n); \</span><br><span class="line">    &#125; else &#123; \</span><br><span class="line">        used_memory -= _n; \</span><br><span class="line">    &#125; \</span><br><span class="line">&#125; while(0)</span><br><span class="line"></span><br><span class="line">// used_memory 初始化</span><br><span class="line">static size_t used_memory = 0;</span><br><span class="line">static int zmalloc_thread_safe = 0;</span><br></pre></td></tr></table></figure>
<h2 id="跟踪used-memory-rss"><a href="#跟踪used-memory-rss" class="headerlink" title="跟踪used_memory_rss"></a>跟踪used_memory_rss</h2><p>used_memory_rss对应的变量server.resident_set_size，该值来自于redis.c中的zmalloc_get_rss函数，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//redis.c</span><br><span class="line"></span><br><span class="line">    /* Sample the RSS here since this is a relatively slow call. */</span><br><span class="line">    server.resident_set_size = zmalloc_get_rss();</span><br></pre></td></tr></table></figure>

<p>这个函数定义在zmalloc.c中，会根据不同的操作系统，读取对应的操作系统分配的内存</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// zmalloc.c</span><br><span class="line"></span><br><span class="line">// 如果是linux环境，则读取proc信息</span><br><span class="line">#if defined(HAVE_PROC_STAT)</span><br><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line">#include &lt;sys/types.h&gt;</span><br><span class="line">#include &lt;sys/stat.h&gt;</span><br><span class="line">#include &lt;fcntl.h&gt;</span><br><span class="line"></span><br><span class="line">size_t zmalloc_get_rss(void) &#123;</span><br><span class="line">    int page = sysconf(_SC_PAGESIZE);</span><br><span class="line">    size_t rss;</span><br><span class="line">    char buf[4096];</span><br><span class="line">    char filename[256];</span><br><span class="line">    int fd, count;</span><br><span class="line">    char *p, *x;</span><br><span class="line"></span><br><span class="line">    snprintf(filename,256,&quot;/proc/%d/stat&quot;,getpid());</span><br><span class="line">    if ((fd = open(filename,O_RDONLY)) == -1) return 0;</span><br><span class="line">    if (read(fd,buf,4096) &lt;= 0) &#123;</span><br><span class="line">        close(fd);</span><br><span class="line">        return 0;</span><br><span class="line">    &#125;</span><br><span class="line">    close(fd);</span><br><span class="line"></span><br><span class="line">    p = buf;</span><br><span class="line">    count = 23; /* RSS is the 24th field in /proc/&lt;pid&gt;/stat */</span><br><span class="line">    while(p &amp;&amp; count--) &#123;</span><br><span class="line">        p = strchr(p,&#x27; &#x27;);</span><br><span class="line">        if (p) p++;</span><br><span class="line">    &#125;</span><br><span class="line">    if (!p) return 0;</span><br><span class="line">    x = strchr(p,&#x27; &#x27;);</span><br><span class="line">    if (!x) return 0;</span><br><span class="line">    *x = &#x27;\0&#x27;;</span><br><span class="line"></span><br><span class="line">    rss = strtoll(p,NULL,10);</span><br><span class="line">    rss *= page;</span><br><span class="line">    return rss;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 如果是apple, 则读取task info</span><br><span class="line">#elif defined(HAVE_TASKINFO)</span><br><span class="line">#include &lt;unistd.h&gt;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line">#include &lt;sys/types.h&gt;</span><br><span class="line">#include &lt;sys/sysctl.h&gt;</span><br><span class="line">#include &lt;mach/task.h&gt;</span><br><span class="line">#include &lt;mach/mach_init.h&gt;</span><br><span class="line"></span><br><span class="line">size_t zmalloc_get_rss(void) &#123;</span><br><span class="line">    task_t task = MACH_PORT_NULL;</span><br><span class="line">    struct task_basic_info t_info;</span><br><span class="line">    mach_msg_type_number_t t_info_count = TASK_BASIC_INFO_COUNT;</span><br><span class="line"></span><br><span class="line">    if (task_for_pid(current_task(), getpid(), &amp;task) != KERN_SUCCESS)</span><br><span class="line">        return 0;</span><br><span class="line">    task_info(task, TASK_BASIC_INFO, (task_info_t)&amp;t_info, &amp;t_info_count);</span><br><span class="line"></span><br><span class="line">    return t_info.resident_size;</span><br><span class="line">&#125;</span><br><span class="line">// 如果都不是，则读取used_memory作为used_memory_rss</span><br><span class="line">#else</span><br><span class="line">size_t zmalloc_get_rss(void) &#123;</span><br><span class="line">    /* If we can&#x27;t get the RSS in an OS-specific way for this system just</span><br><span class="line">     * return the memory usage we estimated in zmalloc()..</span><br><span class="line">     *</span><br><span class="line">     * Fragmentation will appear to be always 1 (no fragmentation)</span><br><span class="line">     * of course... */</span><br><span class="line">    return zmalloc_used_memory();</span><br><span class="line">&#125;</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure>


<h2 id="跟踪used-memory-lua"><a href="#跟踪used-memory-lua" class="headerlink" title="跟踪used_memory_lua"></a>跟踪used_memory_lua</h2><p>used_memory_lua从lua_gc(server.lua,LUA_GCCOUNT,0))*1024LL获取，lua_gc定义在redis\deps\lua\src\lapi.c，通过该函数可以获取LUA引擎占用的内存。（具体lua内部是如何获取的就不清楚了。。）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// deps\lua\src\lapi.c</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line">** Garbage-collection function</span><br><span class="line">*/</span><br><span class="line"></span><br><span class="line">LUA_API int lua_gc (lua_State *L, int what, int data) &#123;</span><br><span class="line">  int res = 0;</span><br><span class="line">  global_State *g;</span><br><span class="line">  lua_lock(L);</span><br><span class="line">  g = G(L);</span><br><span class="line">  switch (what) &#123;</span><br><span class="line">    case LUA_GCSTOP: &#123;</span><br><span class="line">      g-&gt;GCthreshold = MAX_LUMEM;</span><br><span class="line">      break;</span><br><span class="line">    &#125;</span><br><span class="line">    case LUA_GCRESTART: &#123;</span><br><span class="line">      g-&gt;GCthreshold = g-&gt;totalbytes;</span><br><span class="line">      break;</span><br><span class="line">    &#125;</span><br><span class="line">    case LUA_GCCOLLECT: &#123;</span><br><span class="line">      luaC_fullgc(L);</span><br><span class="line">      break;</span><br><span class="line">    &#125;</span><br><span class="line">    case LUA_GCCOUNT: &#123;</span><br><span class="line">      /* GC values are expressed in Kbytes: #bytes/2^10 */</span><br><span class="line">      res = cast_int(g-&gt;totalbytes &gt;&gt; 10);</span><br><span class="line">      break;</span><br><span class="line">    &#125;</span><br><span class="line">    case LUA_GCCOUNTB: &#123;</span><br><span class="line">      res = cast_int(g-&gt;totalbytes &amp; 0x3ff);</span><br><span class="line">      break;</span><br><span class="line">    &#125;</span><br><span class="line">    case LUA_GCSTEP: &#123;</span><br><span class="line">      lu_mem a = (cast(lu_mem, data) &lt;&lt; 10);</span><br><span class="line">      if (a &lt;= g-&gt;totalbytes)</span><br><span class="line">        g-&gt;GCthreshold = g-&gt;totalbytes - a;</span><br><span class="line">      else</span><br><span class="line">        g-&gt;GCthreshold = 0;</span><br><span class="line">      while (g-&gt;GCthreshold &lt;= g-&gt;totalbytes) &#123;</span><br><span class="line">        luaC_step(L);</span><br><span class="line">        if (g-&gt;gcstate == GCSpause) &#123;  /* end of cycle? */</span><br><span class="line">          res = 1;  /* signal it */</span><br><span class="line">          break;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      break;</span><br><span class="line">    &#125;</span><br><span class="line">    case LUA_GCSETPAUSE: &#123;</span><br><span class="line">      res = g-&gt;gcpause;</span><br><span class="line">      g-&gt;gcpause = data;</span><br><span class="line">      break;</span><br><span class="line">    &#125;</span><br><span class="line">    case LUA_GCSETSTEPMUL: &#123;</span><br><span class="line">      res = g-&gt;gcstepmul;</span><br><span class="line">      g-&gt;gcstepmul = data;</span><br><span class="line">      break;</span><br><span class="line">    &#125;</span><br><span class="line">    default: res = -1;  /* invalid option */</span><br><span class="line">  &#125;</span><br><span class="line">  lua_unlock(L);</span><br><span class="line">  return res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="跟踪used-memory-peak"><a href="#跟踪used-memory-peak" class="headerlink" title="跟踪used_memory_peak"></a>跟踪used_memory_peak</h2><p>used_memory_peak对应server.stat_peak_memory。该值每次读取时，都会通过zmalloc_used_memory()获取最新的used_memory的值，并记录used_memory的最大值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//redis.c</span><br><span class="line">        // used_memory是通过时间事件更新的，为防止出现峰值内存小于当前redis使用内存的情况，此时会重新读取一次最新的内存值，并更新峰值内存</span><br><span class="line">        size_t zmalloc_used = zmalloc_used_memory();</span><br><span class="line">        if (zmalloc_used &gt; server.stat_peak_memory)</span><br><span class="line">            server.stat_peak_memory = zmalloc_used;</span><br></pre></td></tr></table></figure>


<h1 id="内存碎片产生原因"><a href="#内存碎片产生原因" class="headerlink" title="内存碎片产生原因"></a>内存碎片产生原因</h1><ul>
<li><p>操作系统使用不连续的内存碎片来提供给内存分配器。<br>当操作系统没有足够的内存时，无法提供整块的内存供redis内存分配器，内存分配器对内存碎片的利用率较低。</p>
</li>
<li><p>内存分配器为加快程序运行，额外使用了内存</p>
</li>
<li><p>内存分配器释放了内存块，但没有将内存返还给系统</p>
</li>
<li><p>分配内存块大小与内存分配器的类型（libc    jemalloc tcmalloc)不同, 产生的内存碎片量也不同。</p>
</li>
<li><p>如果used_memory_peak和used_memory_rss大致相等，且远大于used_memory,则说明额外的内存碎片正在产生。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
</search>
